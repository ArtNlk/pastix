extern "C" %{
/**
 *
 * @file zpotrf_sp2d.jdf
 *
 * PaRSEC 2D algorithm jdf for Cholesky factorization.
 *
 * @copyright 2016-2017 Bordeaux INP, CNRS (LaBRI UMR 5800), Inria,
 *                      Univ. Bordeaux. All rights reserved.
 *
 * @version 6.0.0
 * @author Mathieu Faverge
 * @date 2013-06-24
 * @precisions normal z -> s d c
 *
 **/
#include <parsec.h>
#include <parsec/data_distribution.h>
#include <parsec/private_mempool.h>
#include "common.h"
#include "solver.h"
#include "coeftab_z.h"
#include "pastix_zcores.h"
#include "sopalin_data.h"
#include "pastix_parsec_gpu.h"

%}

/* Globals
 */
descA        [type = "parsec_sparse_matrix_desc_t *" ]
sopalin_data [type = "sopalin_data_t *" ]

forced_pushout [type = "int" hidden = on default = "(0)" ]
datacode  [type = "SolverMatrix*"         hidden = on default = "(sopalin_data->solvmtx)"       ]
cblknbr   [type = "pastix_int_t"          hidden = on default = "(datacode->cblknbr - 1)"       ]
bloknbr   [type = "pastix_int_t"          hidden = on default = "(datacode->bloknbr - 2)"       ]
cblkmax1d [type = "pastix_int_t"          hidden = on default = "(datacode->cblkmax1d)"         ]
cblkmin2d [type = "pastix_int_t"          hidden = on default = "(datacode->cblkmin2d)"         ]
blokmax1d [type = "pastix_int_t"          hidden = on default = "(((datacode->cblktab + cblkmax1d + 1)->fblokptr - datacode->bloktab) - 1)" ]
lowrank   [type = "pastix_lr_t"           hidden = on default = "(sopalin_data->solvmtx->lowrank)"]

p_work    [type = "parsec_memory_pool_t *"]
lwork     [type = "pastix_int_t"]

/**************************************************
 *                   POTRF                        *
 * panel factorization: do trf of diagonal and    *
 *                    : trsm on off-diagonal      *
 **************************************************/
POTRF(k) [high_priority = on]

// Execution space
k = 0 .. cblknbr

browk0    = %{ SolverCblk *cblk = datacode->cblktab + k;     return cblk->brownum; %}
browk1    = %{ SolverCblk *cblk = datacode->cblktab + k;     return cblk->brown2d; %}
lastbrow  = %{ if ( browk0 == browk1 ) return 0; else return datacode->browtab[ browk1 - 1 ]; %}

isTwoD    = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->cblktype & CBLK_TASKS_2D);         %}
firstblok = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->fblokptr - datacode->bloktab) + 1; %}
lastblok  = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return (cblk->fblokptr - datacode->bloktab) - 1; %}

// Parallel partitioning
:descA(0, k, 0)

// Parameters
/* C is A(k) if it's a leaf or get the cblk from the last update */
RW L <- ( browk0 == browk1 ) ? descA(0, k, 0) : C GEMM1D( lastbrow )
     -> !isTwoD ? A GEMM1D(firstblok .. lastblok)
     -> descA(0, k, 0)

CTL ctl -> isTwoD ? ctl OneToTwoD(k, 0 .. (lastblok-firstblok+1))

; %{ return cblknbr - k; %}

BODY
{
    SolverCblk *cblk = datacode->cblktab + k;

    if (!isTwoD) {
        if (!(cblk->cblktype & CBLK_IN_SCHUR))
    	{
            cpucblk_zpotrfsp1d_panel( cblk, L, sopalin_data->diagthreshold, &lowrank );
        }
    }
    else {
        /* Compression between 1D and 2D updates */
        if ( lowrank.compress_when == PastixCompressWhenDuring ) {
            cpucblk_zcompress( PastixLCoef, cblk, lowrank );
        }
    }
}
END

/**
 *       GEMM
 *
 * To have a contiguous range of GEMM to release in the potrf, they are numbered
 * with the indexes of the off-diagonal blocks, diagonal block included.
 * Thus, the diagonal block tasks which doesn't perfom computations are used as
 * DATA_IN tasks. This is mandatory when using the GPU, due to the versioning
 * bumped by the cpu version of the diagonal block that coccurs when computing
 * the diagonal blocks.
 *
 * For all off-diagonal blocks, it updates the trailing matrix with the panel
 * k-th block updating corresponding.
 *
 */
GEMM1D(bloknum)

// Execution space
bloknum = 1 .. blokmax1d

lcblknm = %{ SolverBlok *blok = datacode->bloktab + bloknum; return blok->lcblknm; %}
fcblknm = %{ SolverBlok *blok = datacode->bloktab + bloknum; return blok->fcblknm; %}
first   = %{ SolverCblk *cblk = datacode->cblktab + fcblknm; return cblk->brownum; %}
last    = %{ SolverCblk *cblk = datacode->cblktab + fcblknm; return cblk->brown2d - 1; %}
isTwoD  = %{ SolverCblk *cblk = datacode->cblktab + lcblknm; return cblk->cblktype & CBLK_TASKS_2D; %}

brownum = %{ return datacode->bloktab[bloknum].browind; %} /* -1 if diagonal block */
prev    = %{
    assert( first >= 0 );
    /**
     * If bloknum is a diagonal block, or if it is the first one applied on C,
     * there is no previous
     */
    if ((brownum == -1) || (brownum == first) ) {
        return 0;
    }
    /**
     * Otherwise we return the previous block in the list of blocks facing fcblk
     */
    else {
        assert( brownum > first );
        return datacode->browtab[brownum-1];
    }
    %}
next    = %{
    /**
     * If we are on a diagonal blok, or if we are the last one, there is no next
     */
    if ((brownum == -1) || (brownum >= last) ){
        return 0;
    } else {
        return datacode->browtab[brownum+1];
    }
    %}

n  = %{ if (brownum == -1) return 0; else return blok_rownbr(datacode->bloktab + bloknum); %}
k  = %{ if (brownum == -1) return 0; else return cblk_colnbr(datacode->cblktab + lcblknm); %}
m  = %{ if (brownum == -1) return 0; else {
        if ((datacode->cblktab + lcblknm)->cblktype & CBLK_LAYOUT_2D) {
            return datacode->cblktab[lcblknm].stride - (datacode->bloktab[bloknum].coefind / k);
        } else {
            return datacode->cblktab[lcblknm].stride - datacode->bloktab[bloknum].coefind;
        }
    }%}

// Parallel partitioning
:descA(0, fcblknm, 0)

// Parameters
READ  A  <- (brownum != -1 && !isTwoD) ? L POTRF( lcblknm ) : NULL

RW    C  <- (brownum == -1) || isTwoD ? NULL
         <- (brownum != -1) && !isTwoD && (brownum == first) ? descA( 0, fcblknm, 0 )
         <- (brownum != -1) && !isTwoD && (brownum != first) ? C GEMM1D( prev )

         -> (brownum != -1) && (brownum == last) ? L POTRF( fcblknm )
         -> (brownum != -1) && (brownum != last) ? C GEMM1D( next )

; %{ return cblknbr - ((fcblknm + lcblknm) / 2 ) + last - brownum; %}

BODY [ type=CUDA pushout=forced_pushout devicefct=pastix_parsec_selectgpu_fct ]
#if defined(PASTIX_WITH_CUDA)
{
    /* Never execute the 1D GPU kernel on diagonal blocks, and 2D cblks */
    if ((brownum != -1) && !isTwoD) {
        SolverCblk *lcblk = datacode->cblktab + lcblknm;
        SolverCblk *fcblk = datacode->cblktab + fcblknm;
        SolverBlok *blok  = datacode->bloktab + bloknum;

        if (!(lcblk->cblktype & CBLK_IN_SCHUR)) {
            assert( parsec_body.index == fcblk->gpuid );

#if defined(PASTIX_CUDA_FERMI)
            gpu_zgemmsp_fermi( datacode,
                               PastixLower, PastixConjTrans,
                               descA->d_blocktab[parsec_body.index],
                               lcblk, blok, fcblk,
                               A, A, C,
                               parsec_body.stream );
#else
            gpucblk_zgemmsp( PastixLCoef, PastixLCoef, PastixConjTrans,
                             lcblk, blok, fcblk,
                             A, A, C,
                             &lowrank, parsec_body.stream );
#endif /* defined(PASTIX_CUDA_FERMI) */
        }
    }
}
#endif
END

BODY
{
    /* If diagonal block, or 2D, we skip it */
    if ((brownum != -1) && !isTwoD) {
        SolverCblk *lcblk = datacode->cblktab + lcblknm;
        SolverCblk *fcblk = datacode->cblktab + fcblknm;
        SolverBlok *blok  = datacode->bloktab + bloknum;
        pastix_complex64_t *work = NULL;

        if (!(lcblk->cblktype & CBLK_IN_SCHUR)) {
            if ( lwork > 0 ) {
                work = (pastix_complex64_t *)parsec_private_memory_pop( p_work );
            }

            cpucblk_zgemmsp( PastixLCoef, PastixLCoef, PastixConjTrans,
                             lcblk, blok, fcblk,
                             A, A, C,
                             work, lwork, &lowrank );

            if ( work  ) {
                parsec_private_memory_push( p_work, (void *)work );
            }
        }
    }
}
END

OneToTwoD(k, m)

// Execution space
k    = cblkmin2d .. cblknbr

isTwoD  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->cblktype & CBLK_TASKS_2D);         %}
fblokk  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->fblokptr - datacode->bloktab);     %}
lblokk  = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return (cblk->fblokptr - datacode->bloktab) - 1; %}
m       = 0 .. (isTwoD ? (lblokk-fblokk) : -1 )
noskip  = %{ if (m == 0) {
                 return 1;
             }
             else {
                 SolverBlok *blok = datacode->bloktab + fblokk + m - 1;
                 return ( (blok[0].lcblknm == blok[1].lcblknm) &&
                          (blok[0].fcblknm == blok[1].fcblknm) ) ? 0 : 1+m;
             } %}

first   = %{ if (noskip) { SolverCblk *cblk = datacode->cblktab + k;     return cblk->brown2d; } else { return 0; }%}
last    = %{ if (noskip) { SolverCblk *cblk = datacode->cblktab + k + 1; return cblk->brownum; } else { return 0; }%}

// Parallel partitioning
:descA(0, k, noskip)

// Parameters
READ A <- isTwoD && noskip ? descA(0, k, noskip) : NULL
       /* This cblk is a leaf */
       -> isTwoD && noskip && (first == last) && (m == 0) ? A POTRF2D( k )
       -> isTwoD && noskip && (first == last) && (m != 0) ? C TRSM2D( k, m )

       /* This cblk must receive 2D updates */
       -> isTwoD && noskip && (first <  last) ? C GEMM2D( k, m, first )

CTL  ctl <- (isTwoD) ? ctl POTRF(k)

; %{ return cblknbr - k; %}

BODY
{
    /* Switch from 1D data handlers to 2D data handlers */
}
END

POTRF2D(k)

// Execution space
k       = cblkmin2d .. cblknbr
isTwoD  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->cblktype & CBLK_TASKS_2D);         %}
fblokk  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->fblokptr - datacode->bloktab);     %}
lblokk  = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return (cblk->fblokptr - datacode->bloktab) - 1; %}
first   = %{ SolverCblk *cblk = datacode->cblktab + k;     return cblk->brown2d; %}
last    = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return cblk->brownum; %}

// Parallel partitioning
:descA(0, k, 1)

// Parameters
/* C is A(k) if it's a leaf or get the cblk from the last update */
RW   A  <-  isTwoD & (first == last) ? A OneToTwoD( k, 0 )
        <-  isTwoD & (first <  last) ? C GEMM2D( k, 0, last-1 )
        <- !isTwoD ? NULL

        ->  isTwoD ? A TRSM2D( k, 1 .. (lblokk-fblokk) )
        ->  isTwoD ? descA(0, k, 1)

; %{ return cblknbr - k; %}

BODY
{
    if (isTwoD) {
        SolverCblk *cblk = datacode->cblktab + k;
        /* pastix_int_t  nbpivot = */
        if (!(cblk->cblktype & CBLK_IN_SCHUR))
    	{
            cpucblk_zpotrfsp1d_potrf( cblk, A, sopalin_data->diagthreshold );
        }
    }
}
END

TRSM2D(k, m)

     /* On all the 2D cblk */
k       = cblkmin2d .. cblknbr-1

isTwoD  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->cblktype & CBLK_TASKS_2D);         %}
fblokk  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->fblokptr - datacode->bloktab);     %}
lblokk  = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return (cblk->fblokptr - datacode->bloktab) - 1; %}

m       = 1 .. (isTwoD ? (lblokk-fblokk) : 0 )
noskip  = %{ SolverBlok *blok = datacode->bloktab + fblokk + m - 1;
             return ( (blok[0].lcblknm == blok[1].lcblknm) &&
                      (blok[0].fcblknm == blok[1].fcblknm) ) ? 0 : 1+m; %}

first   = %{ if (noskip) { SolverCblk *cblk = datacode->cblktab + k;           return cblk->brown2d;                        } else { return 0; } %}
last    = %{ if (noskip) { SolverCblk *cblk = datacode->cblktab + k + 1;       return cblk->brownum;                        } else { return 0; } %}
fcblknm = %{ if (noskip) { SolverBlok *blok = datacode->bloktab + fblokk + m;  return blok->fcblknm;                        } else { return 0; } %}
browkb  = %{ if (noskip) { SolverBlok *blok = datacode->bloktab + fblokk + m;  return blok->browind;                        } else { return 0; } %}
fblokn  = %{ if (noskip) { SolverCblk *cblk = datacode->cblktab + fcblknm;     return cblk->fblokptr - datacode->bloktab;   } else { return 0; } %}
lblokn  = %{ if (noskip) { SolverCblk *cblk = datacode->cblktab + fcblknm + 1; return cblk->fblokptr - datacode->bloktab-1; } else { return 0; } %}

// Parallel partitioning
:descA(0, k, noskip)

// Parameters
/* C is A(k) if it's a leaf or get the cblk from the last update */
READ  A   <-  isTwoD ? A POTRF2D( k ) : NULL

RW    C   <-  isTwoD & noskip & (first == last) ? A OneToTwoD( k, m )
          <-  isTwoD & noskip & (first <  last) ? C GEMM2D( k, m, last-1 )
          <-(!isTwoD) | (!noskip) ? NULL
          ->  isTwoD & noskip ? A FWDTOGEMM2D( k, m, 1 .. m )
          ->  isTwoD & noskip ? B GEMM2D( fcblknm, 0 .. (lblokn-fblokn), browkb )
          ->  isTwoD & noskip ? descA(0, k, noskip)

; %{ return cblknbr - k; %}

BODY [ type=CUDA pushout=forced_pushout devicefct=pastix_parsec_selectgpu_fct ]
#if defined(PASTIX_WITH_CUDA)
{
    if( isTwoD && noskip ) {
        SolverCblk *cblk  = datacode->cblktab + k;

        if (!(cblk->cblktype & CBLK_IN_SCHUR)) {
            gpublok_ztrsmsp( PastixLCoef, PastixRight, PastixLower,
                             PastixConjTrans, PastixNonUnit,
                             cblk, m, A, C, &lowrank,
                             parsec_body.stream );
        }
    }
}
#endif
END

BODY
{
    if (isTwoD && noskip) {
        SolverCblk *cblk = datacode->cblktab + k;

        if (!(cblk->cblktype & CBLK_IN_SCHUR)) {
            cpublok_ztrsmsp( PastixLCoef, PastixRight, PastixLower,
                             PastixConjTrans, PastixNonUnit,
                             cblk, m, A, C, &lowrank );
        }
    }
}
END

FWDTOGEMM2D(k, m, n)

// Execution space
k       = cblkmin2d .. cblknbr-1
isTwoD  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->cblktype & CBLK_TASKS_2D);         %}
fblokk  = %{ SolverCblk *cblk = datacode->cblktab + k;     return (cblk->fblokptr - datacode->bloktab);     %}
lblokk  = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return (cblk->fblokptr - datacode->bloktab) - 1; %}

m       = 1 .. (isTwoD ? (lblokk-fblokk) : 0 )
noskipM = %{ SolverBlok *blok = datacode->bloktab + fblokk + m - 1;
             return ( (blok[0].lcblknm == blok[1].lcblknm) &&
                      (blok[0].fcblknm == blok[1].fcblknm) ) ? 0 : 1+m; %}

n       = 1 .. %{ return noskipM ? m : 0; %}
noskipN = %{ SolverBlok *blok = datacode->bloktab + fblokk + n - 1;
             return ( (blok[0].lcblknm == blok[1].lcblknm) &&
                      (blok[0].fcblknm == blok[1].fcblknm) ) ? 0 : 1+n; %}

cblk_n  = %{ SolverBlok *blok = datacode->bloktab + fblokk + n;  return blok->fcblknm; %}
blok_mn = %{
    if( noskipM ) {
      SolverBlok *blokA = datacode->bloktab + fblokk + m;
      SolverCblk *cblkC = datacode->cblktab + cblk_n;
      SolverBlok *blokC = cblkC->fblokptr;
      pastix_int_t frownum = blokC->frownum;
      pastix_int_t lrownum = blokC->lrownum;
      pastix_int_t i = 0, j = 0;

      do {
          frownum = blokC->frownum;
          lrownum = blokC->lrownum;
          i += j;
          j = 1;

          while( (cblk_n < cblknbr) &&
                 (blokC[0].fcblknm == blokC[1].fcblknm) &&
                 (blokC[0].lcblknm == blokC[1].lcblknm) )
          {
              blokC++; j++;
              lrownum = blokC->lrownum;
          }
          blokC++;
      }
      while( !((blokA->frownum >= frownum) &&
               (blokA->lrownum <= lrownum)) );
      return i;
    }
    else
        return 0;
%}
browkb = %{ SolverBlok *blok = datacode->bloktab + fblokk + n;
            return blok->browind; %}

// Parallel partitioning
:descA(0, cblk_n, blok_mn)

// Parameters
READ  A  <- noskipM ? C TRSM2D( k, m ) : NULL
         -> noskipM & noskipN ? A GEMM2D( cblk_n, blok_mn, browkb )

; %{ return cblknbr - k; %}

BODY
{
}
END

/**
 *       GEMM
 *
 * To have a contiguous range of GEMM to release in the potrf, they are numbered
 * with the indexes of the off-diagonal blocks, diagonal block included.
 * Thus, the diagonal block tasks which doesn't perfom computations are used as
 * DATA_IN tasks. This is mandatory when using the GPU, due to the versioning
 * bumped by the cpu version of the diagonal block that coccurs when computing
 * the diagonal blocks.
 *
 * For all off-diagonal blocks, it updates the trailing matrix with the panel
 * k-th block updating corresponding.
 *
 */
GEMM2D(cblk_n, blok_mn, k)

// Execution space
cblk_n  = cblkmin2d+1 .. cblknbr

is2dC   = %{ SolverCblk *cblk = datacode->cblktab + cblk_n;     return (cblk->cblktype & CBLK_TASKS_2D);         %}
fblokn  = %{ SolverCblk *cblk = datacode->cblktab + cblk_n;     return (cblk->fblokptr - datacode->bloktab);     %}
lblokn  = %{ SolverCblk *cblk = datacode->cblktab + cblk_n + 1; return (cblk->fblokptr - datacode->bloktab) - 1; %}

blok_mn = 0 .. (is2dC ? (lblokn-fblokn) : -1)
noskipC = %{ SolverBlok *blok = datacode->bloktab + fblokn + blok_mn - 1;
             return ( (blok[0].lcblknm == blok[1].lcblknm) &&
                      (blok[0].fcblknm == blok[1].fcblknm) ) ? 0 : 1+blok_mn; %}

first   = %{ if (noskipC) { SolverCblk *cblk = datacode->cblktab + cblk_n;     return cblk->brown2d;     }
             else { return 1; }%}
last    = %{ if (noskipC) { SolverCblk *cblk = datacode->cblktab + cblk_n + 1; return cblk->brownum - 1; }
             else { return 0; }%}

k       = first .. last
blok_nk = %{ pastix_int_t nk = datacode->browtab[ k ];
             SolverBlok *blok = datacode->bloktab + nk - 1;
             return ( (blok[0].lcblknm == blok[1].lcblknm) &&
                      (blok[0].fcblknm == blok[1].fcblknm) ) ? 0 : nk; %}

cblk_k  = %{ SolverBlok *blok = datacode->bloktab + blok_nk; return blok->lcblknm; %}
fblokk  = %{ SolverCblk *cblk = datacode->cblktab + cblk_k;  return cblk->fblokptr - datacode->bloktab; %}

is2dA   = %{ SolverCblk *cblk = datacode->cblktab + cblk_k; return (cblk->cblktype & CBLK_TASKS_2D); %}

blok_mk = %{
    if ( blok_nk == 0 ) {
       return 0;
    }
    else {
      SolverBlok *blokA = datacode->bloktab + blok_nk;
      SolverBlok *blokC = datacode->bloktab + fblokn + blok_mn;
      pastix_int_t i = (blokA - datacode->bloktab) - fblokk;

      /* Look for the first blokA that starts after the first blokC */
      while( (blokC->frownum > blokA->lrownum) && (blokA[0].lcblknm == blokA[1].lcblknm) )
      {
         blokA++; i++;
      }
      /* Check if blokA is matching any of the blokC considered together */
      while( (blokA->frownum > blokC->lrownum) &&
             (blokC[0].fcblknm == blokC[1].fcblknm) &&
             (blokC[0].lcblknm == blokC[1].lcblknm))
      {
         blokC++;
      }
      return is_block_inside_fblock( blokA, blokC ) ? i : 0;
    }
%}

todo = (is2dA && is2dC && noskipC && blok_nk && blok_mk)

// Parallel partitioning
:descA(0, cblk_n, noskipC)

// Parameters
READ  A  <-  is2dA & (blok_mk > 0) ? A FWDTOGEMM2D( cblk_k, blok_mk, blok_nk-fblokk ) : NULL
READ  B  <-  is2dA & (blok_nk > 0) ? C TRSM2D( cblk_k, blok_nk-fblokk ) : NULL

RW    C  <- (k == first) ? A OneToTwoD( cblk_n, blok_mn )
         <- (k != first) ? C GEMM2D( cblk_n, blok_mn, k-1 )

         -> (last == k) & (blok_mn == 0) ? A POTRF2D( cblk_n )
         -> (last == k) & (blok_mn != 0) ? C TRSM2D( cblk_n, blok_mn )
         -> (last != k) ? C GEMM2D( cblk_n, blok_mn, k+1 )

; %{ return cblknbr - ( ((k-first) * (cblk_n - cblk_k)) / (last-first+1) ) - cblk_n; %}

BODY [ type=CUDA pushout=forced_pushout devicefct=pastix_parsec_selectgpu_fct ]
#if defined(PASTIX_WITH_CUDA)
{
    /* is2dA && is2dC && noskipC && blok_nk && blok_mk */
    /* Skip the update on diagonal block if upper part */
    if( todo ) {
        SolverCblk *cblk  = datacode->cblktab + cblk_k;
        SolverCblk *fcblk = datacode->cblktab + cblk_n;
        pastix_int_t nk = blok_nk - fblokk;

        if (!(cblk->cblktype & CBLK_IN_SCHUR)) {
            gpublok_zgemmsp( PastixLCoef, PastixLCoef, PastixConjTrans,
                             cblk, fcblk, blok_mk, nk, blok_mn,
                             A, B, C, &lowrank,
                             parsec_body.stream );
        }
    }
}
#endif
END

BODY
{
    /* is2dA && is2dC && noskipC && blok_nk && blok_mk */
    if (todo) {
        SolverCblk  *cblk  = datacode->cblktab + cblk_k;
        SolverCblk  *fcblk = datacode->cblktab + cblk_n;
        pastix_int_t nk = blok_nk - fblokk;

        if (!(cblk->cblktype & CBLK_IN_SCHUR)) {
            cpublok_zgemmsp( PastixLCoef, PastixLCoef, PastixConjTrans,
                             cblk, fcblk, blok_mk, nk, blok_mn,
                             A, B, C, &lowrank );
        }
    }
}
END

extern "C" %{

#if defined(PARSEC_GPU_WITH_CUDA)
#if defined(PASTIX_WITH_CUDA)

int
zpotrf_sp2d_zgemm1d_selectgpu_fct( const __parsec_zpotrf_sp2d_GEMM1D_task_t *this_task,
                              double weight )
{
    pastix_int_t dev_index, gpuid = -2;
    const int brownum = this_task->locals.brownum.value;
    const int isTwoD = this_task->locals.isTwoD.value;

    if ((brownum == -1) || isTwoD) {
      return -2;
    }

    /**
     * Look if one of the GPU owns the C data
     */
    dev_index = this_task->data._f_C.data_in->original->owner_device;
    if (dev_index > 1) {
        gpuid = dev_index - 2;
    }

    /**
     * If not already on the GPU, find the best one
     */
    if ( gpuid == -2 ) {
        __parsec_zpotrf_sp2d_internal_handle_t *__parsec_handle = (__parsec_zpotrf_sp2d_internal_handle_t *)this_task->parsec_handle;
        const __parsec_zpotrf_sp2d_GEMM1D_assignment_t *assignments = &(this_task->locals);
        const int bloknum = assignments->bloknum.value;
        const int lcblknm = assignments->lcblknm.value;
        const int fcblknm = assignments->fcblknm.value;
        SolverMatrix *datacode = __parsec_handle->super._g_datacode;
        SolverCblk *cblk  = (datacode)->cblktab + lcblknm;
        SolverCblk *fcblk = (datacode)->cblktab + fcblknm;
        SolverBlok *blok  = (datacode)->bloktab + bloknum;
        pastix_int_t M, N, K, lda, ldc;
        double gpu_cost, mintime, transfer_cost;
        int dev, nbdevices;
        double cost;

        K = cblk_colnbr( cblk );
        M = cblk->stride;
        M-= (cblk->cblktype & CBLK_LAYOUT_2D) ? blok->coefind / K : blok->coefind;
        N = blok_rownbr( blok );
        lda = cblk->stride;
        ldc = fcblk->stride;

        mintime = cost_gemm( M, N, K, 0 ) / 1.e9; /* CPU_COST in s. */
        mintime = mintime > 0. ? mintime : 0.;

        gpu_cost = cost_gemm( M, N, K, 1 ) / 1.e9;
        gpu_cost = gpu_cost > 0. ? gpu_cost : 0.;

        transfer_cost = sizeof(pastix_complex64_t) / 1.e9 / bandwidth;

        nbdevices = parsec_devices_enabled()-2;
        for( dev = 0; dev < nbdevices; dev++ ) {
            cost = ( 1 + parsec_nbtasks_on_gpu[dev] ) * gpu_cost + transfer_cost;

            /* Compute the transfer cost of A */
            if ( (weight < 5) && (this_task->data._f_A.data_in->original->device_copies[dev+2] != NULL) ) {
                cost += lda * K * transfer_cost;
            }

            /* Compute the transfer cost of B */
            if ( this_task->data._f_C.data_in->original->device_copies[dev+2] != NULL ) {
                cost += ldc * cblk_colnbr( fcblk ) * transfer_cost;
            }

	        if ( cost < mintime )
	        {
		        gpuid = dev;
		        mintime = cost;
	        }
        }
    }

    if ( gpuid >= 0 ) {
        pastix_atomic_inc_32b( &parsec_nbtasks_on_gpu[gpuid] );
    }

    (void)weight;
    return gpuid;
}

int
zpotrf_sp2d_ztrsm2d_selectgpu_fct( const __parsec_zpotrf_sp2d_TRSM2D_task_t *this_task,
                                   double weight )
{
    const __parsec_zpotrf_sp2d_TRSM2D_assignment_t *assignments = &(this_task->locals);
    const int isTwoD = assignments->isTwoD.value;
    const int noskip = assignments->noskip.value;

    pastix_int_t dev_index, gpuid = -2;

    if ( !isTwoD || !noskip ) {
        return -2;
    }

    /**
     * Look if one of the GPU owns the C data
     */
    dev_index = this_task->data._f_C.data_in->original->owner_device;
    if (dev_index > 1) {
        gpuid = dev_index - 2;
    }

    if ( gpuid >= 0 ) {
        pastix_atomic_inc_32b( &parsec_nbtasks_on_gpu[gpuid] );
    }

    (void)weight;
    return gpuid;
}

int
zpotrf_sp2d_zgemm2d_selectgpu_fct( const __parsec_zpotrf_sp2d_GEMM2D_task_t *this_task,
                                   double weight )
{
    __parsec_zpotrf_sp2d_internal_handle_t *__parsec_handle = (__parsec_zpotrf_sp2d_internal_handle_t *)this_task->parsec_handle;
    const __parsec_zpotrf_sp2d_GEMM2D_assignment_t *assignments = &(this_task->locals);
    const int cblk_n = assignments->cblk_n.value;
    const int fblokn = assignments->fblokn.value;
    const int blok_mn = assignments->blok_mn.value;
    const int blok_nk = assignments->blok_nk.value;
    const int cblk_k = assignments->cblk_k.value;
    const int fblokk = assignments->fblokk.value;
    const int blok_mk = assignments->blok_mk.value;
    const int todo = assignments->blok_mk.value;

    SolverMatrix *datacode = __parsec_handle->super._g_datacode;
    SolverCblk *cblk  = (datacode)->cblktab + cblk_k;
    SolverCblk *fcblk = (datacode)->cblktab + cblk_n;
    SolverBlok *blokA = (datacode)->bloktab + fblokk + blok_mk;
    SolverBlok *blokB = (datacode)->bloktab + blok_nk;
    SolverBlok *blokC = (datacode)->bloktab + fblokn + blok_mn;
    pastix_int_t M, N, K, dev_index, gpuid = -2;

    M = blok_rownbr( blokA );
    N = blok_rownbr( blokB );
    K = cblk_colnbr( cblk );

    /**
     * Look if one of the GPU owns the C data
     */
    dev_index = this_task->data._f_C.data_in->original->owner_device;
    if (dev_index > 1) {
        gpuid = dev_index - 2;
    }

    if ( !todo ) {
      return gpuid;
    }

    /**
     * If not already on the GPU, find the best one
     */
    if ( gpuid == -2 ) {
        //parsec_device_t *device;
        double gpu_cost, mintime, transfer_cost;
        int dev, nbdevices;
        double cost;

        //device = parsec_devices_get( 0 );
        mintime  = FLOPS_ZGEMM( M, N, K ) / 1.e9 / 30.; //device->device_dweight; /* CPU_COST */
        gpu_cost = FLOPS_ZGEMM( M, N, K ) / 1.e9;

        transfer_cost = sizeof(pastix_complex64_t) / 1.e9 / bandwidth;

        nbdevices = parsec_devices_enabled()-2;
        for( dev = 0; dev < nbdevices; dev++ ) {
            //device = parsec_devices_get( dev+2 );
            cost = ( weight + parsec_nbtasks_on_gpu[dev] ) * gpu_cost / 1200.; //device->device_dweight;

            /* Compute the transfer cost of A */
            if ( (weight < 20) && (this_task->data._f_A.data_in->original->device_copies[dev+2] != NULL) ) {
                cost += (M*K) * transfer_cost;
            }

            /* Compute the transfer cost of B */
            if ( (weight < 20) && (this_task->data._f_B.data_in->original->device_copies[dev+2] != NULL) ) {
                cost += (N*K) * transfer_cost;
            }

            /* Compute the transfer cost of C */
            if ( this_task->data._f_C.data_in->original->device_copies[dev+2] != NULL ) {
                cost += 2 * transfer_cost *
                    blok_rownbr( blokC ) * cblk_colnbr( fcblk );
            }

	        if ( cost < mintime )
	        {
	            gpuid = dev;
	            mintime = cost;
	        }
        }
    }

    if ( gpuid >= 0 ) {
        pastix_atomic_inc_32b( &parsec_nbtasks_on_gpu[gpuid] );
        pastix_atomic_add_64b( &(pastix_nbflops_on_device[gpuid + 1]),
                               FLOPS_ZGEMM( M, N, K ) );
    }

    (void)weight;
    return gpuid;
}
#else

int
zpotrf_sp2d_zgemm1d_selectgpu_fct( const __parsec_zpotrf_sp2d_GEMM1D_task_t *this_task,
                                   double weight )
{
    (void)this_task; (void)weight;
    return -2;
}

int
zpotrf_sp2d_ztrsm2d_selectgpu_fct( const __parsec_zpotrf_sp2d_TRSM2D_task_t *this_task,
                                   double weight )
{
    (void)this_task; (void)weight;
    return -2;
}

int
zpotrf_sp2d_zgemm2d_selectgpu_fct( const __parsec_zpotrf_sp2d_GEMM2D_task_t *this_task,
                                   double weight )
{
    (void)this_task; (void)weight;
    return -2;
}

#endif /* defined(PASTIX_WITH_CUDA) */
#endif /* defined(PARSEC_GPU_WITH_CUDA) */

%}
